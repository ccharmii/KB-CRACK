#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì´ìƒì¹˜ ë¶„ì„ ê²°ê³¼ í†µí•© ì •ë¦¬ ëª¨ë“ˆ
ì¬ë¬´ ì´ìƒì¹˜ì— ëŒ€í•œ ë¹„ì¬ë¬´ ê·¼ê±°, ë‰´ìŠ¤ ê·¼ê±°, ê´€ë ¨ ë³´ê³ ì„œ ë“±ì„ í†µí•©í•˜ì—¬ JSONìœ¼ë¡œ ì¶œë ¥
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path


class AnomalyIntegrator:
    """ì´ìƒì¹˜ ë¶„ì„ ê²°ê³¼ í†µí•© í´ë˜ìŠ¤"""
    
    def __init__(self, output_dir: str = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            output_dir (str): ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.output_dir = Path(output_dir) if output_dir else Path("./integrated_results")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def load_analysis_files(self, news_analysis_path: str, non_financial_path: str) -> tuple:
        """
        ë¶„ì„ ê²°ê³¼ íŒŒì¼ë“¤ì„ ë¡œë“œ
        
        Args:
            news_analysis_path (str): ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
            non_financial_path (str): ë¹„ì¬ë¬´ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            tuple: (ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼, ë¹„ì¬ë¬´ ë¶„ì„ ê²°ê³¼)
        """
        try:
            # ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ ë¡œë“œ
            with open(news_analysis_path, 'r', encoding='utf-8') as f:
                news_data = json.load(f)
                
            # ë¹„ì¬ë¬´ ë¶„ì„ ê²°ê³¼ ë¡œë“œ
            with open(non_financial_path, 'r', encoding='utf-8') as f:
                non_financial_data = json.load(f)
                
            return news_data, non_financial_data
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None, None
    
    def extract_company_info(self, news_data: Dict) -> Dict:
        """
        ê¸°ì—… ì •ë³´ ì¶”ì¶œ
        
        Args:
            news_data (Dict): ë‰´ìŠ¤ ë¶„ì„ ë°ì´í„°
            
        Returns:
            Dict: ê¸°ì—… ì •ë³´
        """
        company_info = news_data.get("company_info", {})
        
        return {
            "ê¸°ì—…ëª…_í•œê¸€": company_info.get("ê¸°ì—…ëª…", ""),
            "ê¸°ì—…ëª…_ì˜ë¬¸": company_info.get("ì˜ë¬¸ê¸°ì—…ëª…", ""),
            "ì¢…ëª©ì½”ë“œ": company_info.get("ì¢…ëª©ì½”ë“œ", ""),
            "ëŒ€í‘œìëª…": company_info.get("ëŒ€í‘œìëª…", ""),
            "ì—…ì¢…": company_info.get("ì—…ì¢…", ""),
            "ì‹ ìš©ë“±ê¸‰": company_info.get("Current_credit_grade", ""),
            "ì£¼ì†Œ": company_info.get("ì£¼ì†Œ", "")
        }
    
    def match_anomalies_by_metric(self, news_anomalies: List[Dict], 
                                non_financial_results: List[Dict]) -> List[Dict]:
        """
        ë©”íŠ¸ë¦­ëª…ì„ ê¸°ì¤€ìœ¼ë¡œ ë‰´ìŠ¤ ì´ìƒì¹˜ì™€ ë¹„ì¬ë¬´ ê²°ê³¼ë¥¼ ë§¤ì¹­
        
        Args:
            news_anomalies (List[Dict]): ë‰´ìŠ¤ ë¶„ì„ì—ì„œ íƒì§€ëœ ì´ìƒì¹˜ ëª©ë¡
            non_financial_results (List[Dict]): ë¹„ì¬ë¬´ ë¶„ì„ ê²°ê³¼ ëª©ë¡
            
        Returns:
            List[Dict]: í†µí•©ëœ ì´ìƒì¹˜ ë¶„ì„ ê²°ê³¼
        """
        integrated_anomalies = []
        
        # ë¹„ì¬ë¬´ ê²°ê³¼ë¥¼ ë©”íŠ¸ë¦­ë³„ë¡œ ì¸ë±ì‹±
        nf_by_metric = {}
        for nf_result in non_financial_results:
            metric = nf_result.get("metric", "")
            nf_by_metric[metric] = nf_result
        
        # ë‰´ìŠ¤ ì´ìƒì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í†µí•©
        for news_anomaly in news_anomalies:
            anomaly_info = news_anomaly.get("anomaly_info", {})
            metric_name = anomaly_info.get("metric_name", "")
            
            # ë§¤ì¹­ë˜ëŠ” ë¹„ì¬ë¬´ ê²°ê³¼ ì°¾ê¸°
            matching_nf = nf_by_metric.get(metric_name)
            
            # í†µí•© ê²°ê³¼ êµ¬ì„±
            integrated_anomaly = self._create_integrated_anomaly(
                news_anomaly, matching_nf, metric_name
            )
            
            integrated_anomalies.append(integrated_anomaly)
        
        return integrated_anomalies
    
    def _create_integrated_anomaly(self, news_anomaly: Dict, 
                                 non_financial_result: Optional[Dict], 
                                 metric_name: str) -> Dict:
        """
        ê°œë³„ ì´ìƒì¹˜ì— ëŒ€í•œ í†µí•© ê²°ê³¼ ìƒì„±
        
        Args:
            news_anomaly (Dict): ë‰´ìŠ¤ ë¶„ì„ ì´ìƒì¹˜
            non_financial_result (Optional[Dict]): ë§¤ì¹­ë˜ëŠ” ë¹„ì¬ë¬´ ê²°ê³¼
            metric_name (str): ë©”íŠ¸ë¦­ëª…
            
        Returns:
            Dict: í†µí•©ëœ ì´ìƒì¹˜ ê²°ê³¼
        """
        anomaly_info = news_anomaly.get("anomaly_info", {})
        analysis = news_anomaly.get("analysis", {})
        news_evidence = news_anomaly.get("news_evidence", [])
        
        # ê¸°ë³¸ ì´ìƒì¹˜ ì •ë³´
        result = {
            "ë©”íŠ¸ë¦­ëª…": metric_name,
            "ì´ìƒì¹˜_ì„¤ëª…": anomaly_info.get("description", ""),
            "ì‹¬ê°ë„": anomaly_info.get("severity", ""),
            "ë¶„ê¸°": anomaly_info.get("quarter", ""),
            "íƒì§€_ìœ í˜•": anomaly_info.get("type", ""),
            "ë¶„ì„_ì‹œì ": datetime.now().isoformat()
        }
        
        # ë‰´ìŠ¤ ê¸°ë°˜ ë¶„ì„ ê²°ê³¼
        result["ë‰´ìŠ¤_ë¶„ì„"] = {
            "ì£¼ìš”_ì›ì¸": analysis.get("primary_cause", ""),
            "ì‹ ë¢°ë„": analysis.get("confidence_level", 0),
            "ìƒì„¸_ì„¤ëª…": analysis.get("detailed_explanation", ""),
            "ì˜í–¥_í‰ê°€": analysis.get("impact_assessment", ""),
            "ìœ„í—˜_ìˆ˜ì¤€": analysis.get("risk_level", ""),
            "ì§€ì›_ì¦ê±°": analysis.get("supporting_evidence", []),
            "ë‰´ìŠ¤_ì†ŒìŠ¤": analysis.get("news_sources", []),
            "ê´€ë ¨ì„±_í’ˆì§ˆì ìˆ˜": analysis.get("relevance_quality", "")
        }
        
        # ë‰´ìŠ¤ ì¦ê±° ì •ë³´
        result["ë‰´ìŠ¤_ì¦ê±°"] = []
        for news in news_evidence:
            news_info = {
                "ì œëª©": news.get("title", ""),
                "URL": news.get("url", ""),
                "ë°œí–‰ì¼": news.get("published_date", ""),
                "ì¶œì²˜": news.get("source", ""),
                "ê´€ë ¨ì„±_ì ìˆ˜": news.get("hybrid_score", 0),
                "ë‚´ìš©_ìš”ì•½": news.get("content", "")[:200] + "..." if news.get("content") else ""
            }
            result["ë‰´ìŠ¤_ì¦ê±°"].append(news_info)
        
        # ë¹„ì¬ë¬´ ë¶„ì„ ê²°ê³¼ (ìˆëŠ” ê²½ìš°)
        if non_financial_result:
            result["ë¹„ì¬ë¬´_ë¶„ì„"] = {
                "ì„¤ëª…": non_financial_result.get("explanation_ko", ""),
                "ì£¼ìš”_ì›ì¸": non_financial_result.get("drivers", []),
                "ì‹ ë¢°ë„": non_financial_result.get("confidence", 0),
                "ê´€ë ¨_ë³´ê³ ì„œ": [],
                "ê´€ë ¨_ë¬¸ì¥": []
            }
            
            # ì¦ê±° ë¬¸ì„œ ì •ë³´ ì¶”ê°€
            evidence = non_financial_result.get("evidence", [])
            for ev in evidence:
                report_info = {
                    "ë³´ê³ ì„œ_ë²ˆí˜¸": ev.get("rcept_no", ""),
                    "ë¬¸ì„œ_ID": ev.get("chunk_id", ""),
                    "ê´€ë ¨_ë¬¸ì¥": ev.get("snippet", ""),
                    "ì†ŒìŠ¤_ì¸ë±ìŠ¤": ev.get("source_idx", "")
                }
                result["ë¹„ì¬ë¬´_ë¶„ì„"]["ê´€ë ¨_ë³´ê³ ì„œ"].append(report_info)
                result["ë¹„ì¬ë¬´_ë¶„ì„"]["ê´€ë ¨_ë¬¸ì¥"].append(ev.get("snippet", ""))
        else:
            result["ë¹„ì¬ë¬´_ë¶„ì„"] = {
                "ì„¤ëª…": "ë§¤ì¹­ë˜ëŠ” ë¹„ì¬ë¬´ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "ì£¼ìš”_ì›ì¸": [],
                "ì‹ ë¢°ë„": 0,
                "ê´€ë ¨_ë³´ê³ ì„œ": [],
                "ê´€ë ¨_ë¬¸ì¥": []
            }
        
        return result
    
    def create_summary_statistics(self, integrated_anomalies: List[Dict]) -> Dict:
        """
        í†µí•© ë¶„ì„ ê²°ê³¼ ìš”ì•½ í†µê³„ ìƒì„±
        
        Args:
            integrated_anomalies (List[Dict]): í†µí•©ëœ ì´ìƒì¹˜ ëª©ë¡
            
        Returns:
            Dict: ìš”ì•½ í†µê³„
        """
        total_anomalies = len(integrated_anomalies)
        
        # ì‹¬ê°ë„ë³„ ë¶„í¬
        severity_count = {}
        # ë©”íŠ¸ë¦­ë³„ ë¶„í¬
        metric_count = {}
        # ë‰´ìŠ¤ ì‹ ë¢°ë„ í‰ê· 
        news_confidence_scores = []
        # ë¹„ì¬ë¬´ ì‹ ë¢°ë„ í‰ê· 
        nf_confidence_scores = []
        
        for anomaly in integrated_anomalies:
            # ì‹¬ê°ë„ ì§‘ê³„
            severity = anomaly.get("ì‹¬ê°ë„", "Unknown")
            severity_count[severity] = severity_count.get(severity, 0) + 1
            
            # ë©”íŠ¸ë¦­ ì§‘ê³„
            metric = anomaly.get("ë©”íŠ¸ë¦­ëª…", "Unknown")
            metric_count[metric] = metric_count.get(metric, 0) + 1
            
            # ì‹ ë¢°ë„ ì ìˆ˜ ìˆ˜ì§‘
            news_conf = anomaly.get("ë‰´ìŠ¤_ë¶„ì„", {}).get("ì‹ ë¢°ë„", 0)
            if news_conf > 0:
                news_confidence_scores.append(news_conf)
                
            nf_conf = anomaly.get("ë¹„ì¬ë¬´_ë¶„ì„", {}).get("ì‹ ë¢°ë„", 0)
            if nf_conf > 0:
                nf_confidence_scores.append(nf_conf)
        
        return {
            "ì´_ì´ìƒì¹˜_ìˆ˜": total_anomalies,
            "ì‹¬ê°ë„ë³„_ë¶„í¬": severity_count,
            "ë©”íŠ¸ë¦­ë³„_ë¶„í¬": metric_count,
            "í‰ê· _ë‰´ìŠ¤_ì‹ ë¢°ë„": sum(news_confidence_scores) / len(news_confidence_scores) if news_confidence_scores else 0,
            "í‰ê· _ë¹„ì¬ë¬´_ì‹ ë¢°ë„": sum(nf_confidence_scores) / len(nf_confidence_scores) if nf_confidence_scores else 0,
            "ë‰´ìŠ¤_ì¦ê±°_ë³´ìœ _ì´ìƒì¹˜": sum(1 for a in integrated_anomalies if a.get("ë‰´ìŠ¤_ì¦ê±°")),
            "ë¹„ì¬ë¬´_ì¦ê±°_ë³´ìœ _ì´ìƒì¹˜": sum(1 for a in integrated_anomalies if a.get("ë¹„ì¬ë¬´_ë¶„ì„", {}).get("ê´€ë ¨_ë³´ê³ ì„œ"))
        }
    
    def generate_integrated_report(self, news_analysis_path: str, 
                                 non_financial_path: str) -> Dict:
        """
        í†µí•© ì´ìƒì¹˜ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            news_analysis_path (str): ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
            non_financial_path (str): ë¹„ì¬ë¬´ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict: í†µí•©ëœ ë¶„ì„ ë¦¬í¬íŠ¸
        """
        print("ğŸ”„ ì´ìƒì¹˜ ë¶„ì„ ê²°ê³¼ í†µí•© ì‹œì‘...")
        
        # ë¶„ì„ íŒŒì¼ ë¡œë“œ
        news_data, non_financial_data = self.load_analysis_files(
            news_analysis_path, non_financial_path
        )
        
        if not news_data or not non_financial_data:
            return {"error": "ë¶„ì„ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨"}
        
        # ê¸°ì—… ì •ë³´ ì¶”ì¶œ
        company_info = self.extract_company_info(news_data)
        
        # ì´ìƒì¹˜ ë§¤ì¹­ ë° í†µí•©
        news_anomalies = news_data.get("anomaly_news_analyses", [])
        non_financial_results = non_financial_data.get("results", [])
        
        integrated_anomalies = self.match_anomalies_by_metric(
            news_anomalies, non_financial_results
        )
        
        # ìš”ì•½ í†µê³„ ìƒì„±
        summary_stats = self.create_summary_statistics(integrated_anomalies)
        
        # ìµœì¢… ë¦¬í¬íŠ¸ êµ¬ì„±
        integrated_report = {
            "ë¶„ì„_ë©”íƒ€ë°ì´í„°": {
                "ìƒì„±_ì‹œê°„": datetime.now().isoformat(),
                "ë‰´ìŠ¤_ë¶„ì„_íŒŒì¼": str(news_analysis_path),
                "ë¹„ì¬ë¬´_ë¶„ì„_íŒŒì¼": str(non_financial_path),
                "ë¶„ì„_ë°©ë²•ë¡ ": {
                    "ë‰´ìŠ¤_ë¶„ì„": news_data.get("methodology", {}),
                    "í†µí•©_ë°©ì‹": "ë©”íŠ¸ë¦­ëª… ê¸°ì¤€ ë§¤ì¹­"
                }
            },
            "ê¸°ì—…_ì •ë³´": company_info,
            "ìš”ì•½_í†µê³„": summary_stats,
            "í†µí•©_ì´ìƒì¹˜_ë¶„ì„": integrated_anomalies
        }
        
        print(f"âœ… í†µí•© ë¶„ì„ ì™„ë£Œ: {len(integrated_anomalies)}ê°œ ì´ìƒì¹˜ ì²˜ë¦¬")
        return integrated_report
    
    def save_integrated_report(self, report: Dict, filename: str = None) -> str:
        """
        í†µí•© ë¦¬í¬íŠ¸ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            report (Dict): í†µí•© ë¦¬í¬íŠ¸
            filename (str): ì €ì¥í•  íŒŒì¼ëª… (ê¸°ë³¸ê°’: ìë™ ìƒì„±)
            
        Returns:
            str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            corp_name = report.get("ê¸°ì—…_ì •ë³´", {}).get("ê¸°ì—…ëª…_í•œê¸€", "Unknown")
            filename = f"integrated_anomaly_report.json"
        
        filepath = self.output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ í†µí•© ë¦¬í¬íŠ¸ ì €ì¥: {filepath}")
        return str(filepath)
    

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ì˜ˆì‹œ"""
    
    # ì˜ˆì‹œ íŒŒì¼ ê²½ë¡œ (ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”)
    news_analysis_file = "analysis_results/ì‚¼ì„±ì „ì/anomaly_news_analysis.json"
    non_financial_file = "analysis_results/ì‚¼ì„±ì „ì/non_financial_reasoning.json"
    
    # í†µí•©ê¸° ì´ˆê¸°í™”
    integrator = AnomalyIntegrator(output_dir="./ì‚¼ì„±ì „ì")
    
    try:
        # í†µí•© ë¦¬í¬íŠ¸ ìƒì„±
        report = integrator.generate_integrated_report(
            news_analysis_file, 
            non_financial_file
        )
        
        if "error" not in report:
            # JSON ë¦¬í¬íŠ¸ ì €ì¥
            json_path = integrator.save_integrated_report(report)
            
            # Excel ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± (ì˜µì…˜)
            
            print("\n" + "="*60)
            print("ğŸ‰ ì´ìƒì¹˜ ë¶„ì„ ê²°ê³¼ í†µí•© ì™„ë£Œ!")
            print(f"ğŸ“‹ JSON ë¦¬í¬íŠ¸: {json_path}")

            print("="*60)
            
            # ê°„ë‹¨í•œ ìš”ì•½ ì¶œë ¥
            summary = report.get("ìš”ì•½_í†µê³„", {})
            print(f"\nğŸ“Š ìš”ì•½:")
            print(f"   - ì´ ì´ìƒì¹˜: {summary.get('ì´_ì´ìƒì¹˜_ìˆ˜', 0)}ê°œ")
            print(f"   - í‰ê·  ë‰´ìŠ¤ ì‹ ë¢°ë„: {summary.get('í‰ê· _ë‰´ìŠ¤_ì‹ ë¢°ë„', 0):.2f}")
            print(f"   - í‰ê·  ë¹„ì¬ë¬´ ì‹ ë¢°ë„: {summary.get('í‰ê· _ë¹„ì¬ë¬´_ì‹ ë¢°ë„', 0):.2f}")
            
        else:
            print(f"âŒ í†µí•© ë¶„ì„ ì‹¤íŒ¨: {report.get('error')}")
            
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


if __name__ == "__main__":
    main()
