# -*- coding: utf-8 -*-
"""
ë¹„ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ íƒì§€ ë©”ì¸ ëª¨ë“ˆ
ê¸°ì¡´ main.pyë¥¼ ê¸°ë°˜ìœ¼ë¡œ í†µí•© ì‹œìŠ¤í…œìš©ìœ¼ë¡œ ìˆ˜ì •
"""

import os
import uuid
import json
import time
from datetime import datetime, date
from typing import List, Dict

from .config import DATA_DIR, DB_FILE
from .dart_api import list_regular_reports, ensure_report_files
from .db import open_db, upsert_filings, insert_chunks, insert_scores_json
from .indexer import build_or_load_faiss, ingest_texts, get_retriever
from .indicators import load_indicators
from .evaluator import evaluate_quarter
from .json_out import write_quarter_json, append_global_jsonl


def corp_root_path(code: str) -> str:
    """ê¸°ì—…ë³„ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ ìƒì„±"""
    return os.path.join(DATA_DIR, code)


def _qkey(q: str):
    """ë¶„ê¸° ì •ë ¬ìš© í‚¤ ìƒì„± (YYYYQn â†’ (YYYY, n))"""
    return (int(q[:4]), int(q[-1]))


def _result_path(corp_root: str, quarter: str) -> str:
    """ë¶„ê¸°ë³„ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ"""
    res_dir = os.path.join(corp_root, "results")
    os.makedirs(res_dir, exist_ok=True)
    return os.path.join(res_dir, f"{quarter}_nfr_scores.json")


def _result_exists(corp_root: str, quarter: str) -> bool:
    """ë¶„ê¸°ë³„ ê²°ê³¼ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    p = _result_path(corp_root, quarter)
    return os.path.exists(p) and os.path.getsize(p) > 10


def run_for_corp(corp_code: str, asof: date = None, force: bool = False) -> Dict:
    """
    ê¸°ì—…ë³„ ë¹„ì¬ë¬´ì§€í‘œ ë¶„ì„ ì‹¤í–‰ (í†µí•© ì‹œìŠ¤í…œìš©)
    
    Args:
        corp_code (str): DART ê¸°ì—…ì½”ë“œ 8ìë¦¬
        asof (date): ê¸°ì¤€ì¼ (ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
        force (bool): ê¸°ì¡´ ê²°ê³¼ ë¬´ì‹œí•˜ê³  ì¬ì‹¤í–‰ ì—¬ë¶€
        
    Returns:
        Dict: ë¹„ì¬ë¬´ë¶„ì„ ê²°ê³¼
    """
    if asof is None:
        asof = date.today()
        
    print(f"ğŸ“‹ ë¹„ì¬ë¬´ì§€í‘œ ë¶„ì„ ì‹œì‘: {corp_code} (ê¸°ì¤€ì¼: {asof.isoformat()})")
    
    start_time = time.perf_counter()
    
    try:
        # 1. Aìœ í˜• ì •ê¸°ë³´ê³ ì„œ ìˆ˜ì§‘
        print("  - ì •ê¸°ë³´ê³ ì„œ ìˆ˜ì§‘ ì¤‘...")
        all_filings = list_regular_reports(corp_code, asof=asof)
        
        if not all_filings:
            return {
                "success": False,
                "error": "ì¡°íšŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "corp_code": corp_code,
                "analysis_date": datetime.now().isoformat()
            }

        corp_name = all_filings[0].get("corp_name", "")
        
        # ë¶„ê¸°ë³„ ë¬¶ìŒ
        by_q: Dict[str, List[Dict]] = {}
        for f in all_filings:
            by_q.setdefault(f["quarter"], []).append(f)
            
        quarters_avail = sorted(by_q.keys(), key=_qkey, reverse=True)
        targets = quarters_avail[:4]  # ìµœì‹  4ê°œ ë¶„ê¸°
        
        print(f"  - ëŒ€ìƒ ë¶„ê¸°: {targets}")

        # 2. íŒŒì¼ ì €ì¥
        corp_root = corp_root_path(corp_code)
        os.makedirs(corp_root, exist_ok=True)
        
        target_filings = [f for q in targets for f in by_q[q]]
        saved = ensure_report_files(corp_root, target_filings)
        for s in saved:
            s["meta"]["path"] = s["path"]

        has_new = any(s.get("is_new") for s in saved)
        new_quarters = sorted({s["meta"]["quarter"] for s in saved if s.get("is_new")}, 
                             key=_qkey, reverse=True)
        
        print(f"  - íŒŒì¼ ì €ì¥: {len(saved)}ê°œ (ì‹ ê·œ: {sum(1 for s in saved if s.get('is_new'))}ê°œ)")

        # 3. DB ì—…ë°ì´íŠ¸
        db = open_db(os.path.join(corp_root, DB_FILE))
        upsert_filings(db, [s["meta"] for s in saved])

        # 4. ì¸ë±ìŠ¤ êµ¬ì¶•
        print("  - í…ìŠ¤íŠ¸ ì¸ë±ì‹±...")
        vs = build_or_load_faiss(corp_root)
        
        if vs is None or has_new:
            vs, texts, metas = ingest_texts(corp_root, saved, corp_code)
            rows = [{
                "id": m["chunk_id"], "rcept_no": m["rcept_no"], "quarter": m["quarter"],
                "corp_code": corp_code, "start": 0, "end": len(t), "content": t
            } for t, m in zip(texts, metas)]
            if rows:
                insert_chunks(db, rows)

        # 5. ë¶„ê¸°ë³„ í‰ê°€
        indicators = load_indicators()
        print(f"  - ë¹„ì¬ë¬´ì§€í‘œ í‰ê°€ ({len(indicators)}ê°œ ì§€í‘œ)...")
        
        evaluation_results = {}
        
        for q in targets:
            if _result_exists(corp_root, q) and not force:
                print(f"    â€¢ {q}: ê¸°ì¡´ ê²°ê³¼ ì¬ì‚¬ìš©")
                # ê¸°ì¡´ ê²°ê³¼ ë¡œë“œ
                try:
                    with open(_result_path(corp_root, q), 'r', encoding='utf-8') as f:
                        result_data = json.load(f)
                        evaluation_results[q] = result_data.get("indicators", [])
                except:
                    pass
                continue
                
            if q not in by_q or not by_q[q]:
                print(f"    â€¢ {q}: ë¬¸ì„œ ì—†ìŒ")
                continue

            print(f"    â€¢ {q} í‰ê°€ ì¤‘...")
            retriever = get_retriever(vs, quarter=q)
            res = evaluate_quarter(retriever, q, indicators)

            if res:
                evaluation_results[q] = res
                
                # DB ì €ì¥
                rows = [{
                    "id": str(uuid.uuid4()),
                    "corp_code": corp_code,
                    "quarter": q,
                    "indicator_id": item["indicator_id"],
                    "indicator_name": item["indicator_name"],
                    "pillar": item["pillar"],
                    "score": float(item["score"]),
                    "confidence": float(item.get("confidence", 0.5)),
                    "rationale": item.get("rationale", "")[:2000],
                    "evidence_json": json.dumps(item.get("evidence", []), ensure_ascii=False),
                    "created_at": datetime.now().isoformat(timespec="seconds"),
                } for item in res]
                
                insert_scores_json(db, rows)
                
                # JSON íŒŒì¼ ì €ì¥
                write_quarter_json(corp_root, corp_code, corp_name, q, res)

        # 6. ê²°ê³¼ ì •ë¦¬
        end_time = time.perf_counter()
        
        # ìµœì‹  ë¶„ê¸° ê²°ê³¼ë¡œ ìš”ì•½ ìƒì„±
        latest_quarter = targets[0] if targets else None
        latest_results = evaluation_results.get(latest_quarter, []) if latest_quarter else []
        
        # ìœ„í—˜ë„ ìš”ì•½
        risk_summary = _calculate_risk_summary(latest_results)
        
        final_result = {
            "success": True,
            "corp_code": corp_code,
            "corp_name": corp_name,
            "analysis_date": datetime.now().isoformat(),
            "analysis_duration": round(end_time - start_time, 2),
            "analyzed_quarters": list(evaluation_results.keys()),
            "latest_quarter": latest_quarter,
            "latest_quarter_results": latest_results,
            "risk_summary": risk_summary,
            "total_documents": len(saved),
            "total_indicators": len(indicators),
            "evaluation_results_by_quarter": evaluation_results
        }
        
        print(f"âœ… ë¹„ì¬ë¬´ì§€í‘œ ë¶„ì„ ì™„ë£Œ ({final_result['analysis_duration']}ì´ˆ)")
        print(f"  - ë¶„ì„ ë¶„ê¸°: {len(evaluation_results)}ê°œ")
        print(f"  - ìœ„í—˜ ìˆ˜ì¤€: {risk_summary.get('overall_risk_level', 'Unknown')}")
        
        return final_result
        
    except Exception as e:
        print(f"âŒ ë¹„ì¬ë¬´ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "corp_code": corp_code,
            "analysis_date": datetime.now().isoformat()
        }


def _calculate_risk_summary(quarter_results: List[Dict]) -> Dict:
    """ë¶„ê¸° ê²°ê³¼ë¡œë¶€í„° ìœ„í—˜ë„ ìš”ì•½ ê³„ì‚°"""
    
    if not quarter_results:
        return {
            "overall_risk_level": "ë°ì´í„° ì—†ìŒ",
            "average_score": 0,
            "risk_indicators": []
        }
    
    # ì ìˆ˜ë³„ í†µê³„
    scores = [item.get("score", 2) for item in quarter_results]
    avg_score = sum(scores) / len(scores) if scores else 2
    
    # ìœ„í—˜ ì§€í‘œ (ì ìˆ˜ 2 ì´í•˜)
    risk_indicators = [
        {
            "indicator": item.get("indicator_name", ""),
            "pillar": item.get("pillar", ""),
            "score": item.get("score", 2),
            "grade": item.get("grade_label", ""),
            "confidence": item.get("confidence", 0)
        }
        for item in quarter_results
        if item.get("score", 2) <= 2
    ]
    
    # ì „ì²´ ìœ„í—˜ ìˆ˜ì¤€ ê²°ì •
    if avg_score >= 3.5:
        overall_risk = "ë‚®ìŒ"
    elif avg_score >= 2.5:
        overall_risk = "ë³´í†µ"
    elif avg_score >= 1.5:
        overall_risk = "ì£¼ì˜"
    else:
        overall_risk = "ë†’ìŒ"
    
    return {
        "overall_risk_level": overall_risk,
        "average_score": round(avg_score, 2),
        "total_indicators": len(quarter_results),
        "risk_indicators_count": len(risk_indicators),
        "risk_indicators": risk_indicators[:5],  # ìƒìœ„ 5ê°œë§Œ
        "score_distribution": {
            "excellent": len([s for s in scores if s >= 4]),
            "good": len([s for s in scores if 3 <= s < 4]),
            "neutral": len([s for s in scores if 2 <= s < 3]),
            "poor": len([s for s in scores if 1 <= s < 2]),
            "critical": len([s for s in scores if s < 1])
        }
    }



if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_corp_code = "00126380"  # ì‚¼ì„±ì „ì
    
    result = run_for_corp(
        corp_code=test_corp_code,
        asof=date.today(),
        force=False
    )
    
    if result.get("success"):
        print(f"\në¹„ì¬ë¬´ë¶„ì„ ì„±ê³µ:")
        print(f"- ê¸°ì—…: {result.get('corp_name')}")
        print(f"- ë¶„ì„ ë¶„ê¸°: {len(result.get('analyzed_quarters', []))}ê°œ")
        print(f"- ìœ„í—˜ ìˆ˜ì¤€: {result['risk_summary']['overall_risk_level']}")
        
        # # ì´ìƒì¹˜ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        # anomalies = extract_nfr_anomalies(result)
        # print(f"- íƒì§€ëœ ì´ìƒì¹˜: {len(anomalies)}ê°œ")
        
    else:
        print(f"ë¹„ì¬ë¬´ë¶„ì„ ì‹¤íŒ¨: {result.get('error')}")