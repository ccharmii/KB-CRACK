# -*- coding: utf-8 -*-
"""
í†µí•© ì‹ ìš©ìœ„í—˜ ë¶„ì„ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±ê¸° (ìˆ˜ì •ëœ ë²„ì „)
ë‰´ìŠ¤ ë¶„ì„ì„ ì œì™¸í•œ ì¬ë¬´ì§€í‘œ, ë¹„ì¬ë¬´ì§€í‘œ, ê·¼ê±° ë¶„ì„ì„ í†µí•©í•˜ì—¬ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv

load_dotenv()

class CreditRiskReportGenerator:
    """ì‹ ìš©ìœ„í—˜ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self, model="gpt-4o-mini"):
        """
        ë¦¬í¬íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™”
        
        Args:
            model: ì‚¬ìš©í•  LLM ëª¨ë¸
        """
        self.llm = ChatOpenAI(model=model, temperature=0.3)
        
    def load_analysis_results(self, result_dir: str) -> Dict[str, Any]:
        """
        ë¶„ì„ ê²°ê³¼ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ë¡œë“œ
        
        Args:
            result_dir: ë¶„ì„ ê²°ê³¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            
        Returns:
            Dict: í†µí•©ëœ ë¶„ì„ ê²°ê³¼
        """
        results = {
            "financial_analysis": None,
            "financial_anomalies": None,
            "non_financial_analysis": None,
            "integrated_anomaly_analysis": None
        }
        
        # ì¬ë¬´ë¶„ì„ ì›ë³¸ ë°ì´í„° ë¡œë“œ
        financial_analysis_file = os.path.join(result_dir, "financial_analysis.json")
        if os.path.exists(financial_analysis_file):
            try:
                with open(financial_analysis_file, 'r', encoding='utf-8') as f:
                    results["financial_analysis"] = json.load(f)
                print("âœ… ì¬ë¬´ë¶„ì„ ì›ë³¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ì¬ë¬´ë¶„ì„ ì›ë³¸ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        
        # ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ ë¡œë“œ
        financial_anomalies_file = os.path.join(result_dir, "financial_anomalies.json")
        if os.path.exists(financial_anomalies_file):
            try:
                with open(financial_anomalies_file, 'r', encoding='utf-8') as f:
                    results["financial_anomalies"] = json.load(f)
                print(f"âœ… ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ ë¡œë“œ ì™„ë£Œ: {len(results['financial_anomalies'])}ê°œ")
            except Exception as e:
                print(f"âŒ ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        
        # ë¹„ì¬ë¬´ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        nfr_file = os.path.join(result_dir, "non_financial_analysis.json")
        if os.path.exists(nfr_file):
            try:
                with open(nfr_file, 'r', encoding='utf-8') as f:
                    results["non_financial_analysis"] = json.load(f)
                print("âœ… ë¹„ì¬ë¬´ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ë¹„ì¬ë¬´ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        
        # í†µí•© ì´ìƒì¹˜ ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        integrated_file = os.path.join(result_dir, "integrated_anomaly_report.json")
        if os.path.exists(integrated_file):
            try:
                with open(integrated_file, 'r', encoding='utf-8') as f:
                    integrated_data = json.load(f)
                    results["integrated_anomaly_analysis"] = integrated_data.get("í†µí•©_ì´ìƒì¹˜_ë¶„ì„", [])
                print("âœ… í†µí•© ì´ìƒì¹˜ ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ í†µí•© ì´ìƒì¹˜ ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        
        return results
        
    def _calculate_comprehensive_risk_score(self, all_results: Dict[str, Any]) -> Dict[str, Any]:
        """ì¢…í•© ì‹ ìš©ìœ„í—˜ ì ìˆ˜ ê³„ì‚°"""
        
        base_score = 100
        
        # ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ë¡œ ì¸í•œ ê°ì 
        financial_penalty = 0
        financial_anomalies = all_results.get("financial_anomalies")
        if financial_anomalies:
            for metric_name, details in financial_anomalies.items():
                severity = details.get("severity", "Medium") if isinstance(details, dict) else "Medium"
                if severity == "High":
                    financial_penalty += 15
                elif severity == "Medium":
                    financial_penalty += 8
                else:
                    financial_penalty += 3
        
        # ë¹„ì¬ë¬´ì§€í‘œë¡œ ì¸í•œ ê°ì 
        nfr_penalty = 0
        nfr_data = all_results.get("non_financial_analysis")
        if nfr_data:
            risk_summary = nfr_data.get("risk_summary", {})
            risk_level = risk_summary.get("overall_risk_level", "ë³´í†µ")
            
            if risk_level == "ë†’ìŒ":
                nfr_penalty += 25
            elif risk_level == "ì£¼ì˜":
                nfr_penalty += 15
            elif risk_level == "ë³´í†µ":
                nfr_penalty += 8
            
            # ê°œë³„ ì§€í‘œ ì ìˆ˜ë„ ê³ ë ¤
            latest_results = nfr_data.get("latest_quarter_results", [])
            for result in latest_results:
                score = result.get("score", 3)
                if score <= 1:
                    nfr_penalty += 5
                elif score <= 2:
                    nfr_penalty += 3
        
        # ìµœì¢… ì ìˆ˜ ê³„ì‚°
        final_score = max(0, base_score - financial_penalty - nfr_penalty)
        
        # ë“±ê¸‰ ê²°ì •
        if final_score >= 90:
            grade = "AAA"
            risk_level = "ë§¤ìš° ë‚®ìŒ"
        elif final_score >= 80:
            grade = "AA"
            risk_level = "ë‚®ìŒ"
        elif final_score >= 70:
            grade = "A"
            risk_level = "ë³´í†µ"
        elif final_score >= 60:
            grade = "BBB"
            risk_level = "ì£¼ì˜"
        elif final_score >= 50:
            grade = "BB"
            risk_level = "ìœ„í—˜"
        else:
            grade = "B"
            risk_level = "ê³ ìœ„í—˜"
        
        return {
            "score": final_score,
            "grade": grade,
            "risk_level": risk_level,
            "breakdown": {
                "financial_penalty": financial_penalty,
                "non_financial_penalty": nfr_penalty
            },
            "component_scores": {
                "financial": max(0, 100 - financial_penalty),
                "non_financial": max(0, 100 - nfr_penalty)
            }
        }
    
    def _extract_quarterly_trend_data(self, financial_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ê¸°ë³„ ì¬ë¬´ì§€í‘œ ë³€í™” ì¶”ì„¸ ë°ì´í„° ì¶”ì¶œ"""
        
        if not financial_data:
            return {}
            
        # ì£¼ìš”ì§€í‘œ ì‹œê³„ì—´ ë¶„ì„ ë°ì´í„° ì¶”ì¶œ
        quarterly_data = financial_data.get("ì£¼ìš”ì§€í‘œ_ì‹œê³„ì—´_ë¶„ì„", {})
        
        # ë¶„ê¸°ë³„ ë°ì´í„°ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_quarters = sorted(quarterly_data.keys())
        
        trend_analysis = {}
        
        for i, quarter in enumerate(sorted_quarters):
            if i > 0:  # ì´ì „ ë¶„ê¸°ì™€ ë¹„êµ
                prev_quarter = sorted_quarters[i-1]
                current_data = quarterly_data[quarter]
                prev_data = quarterly_data[prev_quarter]
                
                quarter_trend = {}
                for metric, current_value in current_data.items():
                    if metric in prev_data:
                        prev_value = prev_data[metric]
                        if prev_value != 0:
                            change_rate = ((current_value - prev_value) / prev_value) * 100
                            quarter_trend[metric] = {
                                "current": current_value,
                                "previous": prev_value,
                                "change_rate": round(change_rate, 2),
                                "direction": "ì¦ê°€" if change_rate > 0 else "ê°ì†Œ" if change_rate < 0 else "ë³€í™”ì—†ìŒ"
                            }
                
                trend_analysis[quarter] = quarter_trend
        
        return trend_analysis
    
    def _find_similar_cases(self, anomalies: Dict[str, Any], company_info: Dict[str, Any]) -> List[Dict]:
        """ìœ ì‚¬í•œ ì´ìƒì¹˜ ì‚¬ë¡€ ê²€ìƒ‰ (ì˜ˆì‹œ ë°ì´í„°)"""
        
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ê²€ìƒ‰
        similar_cases = [
            {
                "company": "LGì „ì",
                "year": "2023",
                "anomaly_type": "ROE í•˜ë½",
                "initial_grade": "A+",
                "final_grade": "A",
                "recovery_period": "6ê°œì›”",
                "actions_taken": ["ë¹„ìš©ì ˆê°", "ì‚¬ì—…êµ¬ì¡° ê°œí¸", "R&D íˆ¬ì ì¦ëŒ€"]
            },
            {
                "company": "SKí•˜ì´ë‹‰ìŠ¤",
                "year": "2022",
                "anomaly_type": "ë§¤ì¶œì•¡ì¦ê°€ìœ¨ ë‘”í™”",
                "initial_grade": "AA-",
                "final_grade": "A+",
                "recovery_period": "9ê°œì›”",
                "actions_taken": ["ì‹ ì œí’ˆ ì¶œì‹œ", "í•´ì™¸ì‹œì¥ í™•ì¥", "ì›ê°€ì ˆê°"]
            }
        ]
        
        return similar_cases
    
    def generate_ai_analysis_summary(self, all_results: Dict[str, Any], risk_assessment: Dict[str, Any]) -> str:
        """AI ì¢…í•© ë¶„ì„ ìš”ì•½ ìƒì„±"""
        
        summary_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì‹ ìš©ìœ„í—˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ 1-2ì¤„ì˜ ê°„ê²°í•œ AI ì¢…í•© ë¶„ì„ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜: {financial_anomalies_count}ê°œ
ë¹„ì¬ë¬´ì§€í‘œ ìœ„í—˜ìˆ˜ì¤€: {nfr_risk_level}
ì¢…í•© ìœ„í—˜ë“±ê¸‰: {risk_grade}
ì¢…í•© ì ìˆ˜: {risk_score}/100

í•µì‹¬ ì´ìƒì¹˜:
{key_anomalies}

1-2ì¤„ë¡œ í•µì‹¬ ë¦¬ìŠ¤í¬ì™€ ì „ë°˜ì ì¸ ì‹ ìš©ìƒíƒœë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.
        """)
        
        chain = summary_prompt | self.llm | StrOutputParser()
        
        try:
            financial_anomalies = all_results.get("financial_anomalies", {})
            nfr_data = all_results.get("non_financial_analysis", {})
            
            key_anomalies = []
            if financial_anomalies:
                for metric, details in list(financial_anomalies.items())[:3]:  # ìƒìœ„ 3ê°œë§Œ
                    if isinstance(details, dict):
                        key_anomalies.append(f"- {metric}: {details.get('description', '')}")
            
            summary = chain.invoke({
                "financial_anomalies_count": len(financial_anomalies) if financial_anomalies else 0,
                "nfr_risk_level": nfr_data.get("risk_summary", {}).get("overall_risk_level", "ì•Œ ìˆ˜ ì—†ìŒ"),
                "risk_grade": risk_assessment["grade"],
                "risk_score": risk_assessment["score"],
                "key_anomalies": "\n".join(key_anomalies) or "ì£¼ìš” ì´ìƒì¹˜ ì—†ìŒ"
            })
            
            return summary.strip()
            
        except Exception as e:
            return f"AI ë¶„ì„ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def generate_executive_summary(self, all_results: Dict[str, Any], risk_assessment: Dict[str, Any], 
                                 company_info: Dict[str, Any]) -> str:
        """ê²½ì˜ì§„ìš© ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        summary_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì‹ ìš©ìœ„í—˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²½ì˜ì§„ìš© ì¢…í•© ìš”ì•½ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

## ê¸°ì—… ì •ë³´
ê¸°ì—…ëª…: {company_name}
í˜„ì¬ ì‹ ìš©ë“±ê¸‰: {current_grade}
ë¶„ì„ ëŒ€ìƒ ë“±ê¸‰: {new_grade}

## ì¢…í•© ìœ„í—˜ í‰ê°€
- ì ìˆ˜: {score}ì /100ì 
- ë“±ê¸‰: {grade}
- ìœ„í—˜ìˆ˜ì¤€: {risk_level}

## ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ ë¶„ì„
{financial_anomalies_summary}

## ë¹„ì¬ë¬´ì§€í‘œ ë¶„ì„
{non_financial_summary}

## ê·¼ê±° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
{evidence_insights}

ë‹¤ìŒ êµ¬ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

# {company_name} ì‹ ìš©ìœ„í—˜ ë¶„ì„ ìš”ì•½ ë¦¬í¬íŠ¸

## ğŸ” AI ì¢…í•© ë¶„ì„ ìš”ì•½
{ai_summary}

## ğŸ“Š ì˜ˆìƒ ì‹ ìš©ë“±ê¸‰ ë³€í™”
í˜„ì¬: {current_grade} â†’ ì˜ˆìƒ: {new_grade}
ë³€í™” ì‚¬ìœ : [ì£¼ìš” ìœ„í—˜ìš”ì¸ ìš”ì•½]

## âš ï¸ ì£¼ìš” ìœ„í—˜ ìš”ì†Œ
### ì¬ë¬´ì§€í‘œ ìœ„í—˜
[ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ë³„ ìœ„í—˜ë„ ë° ì˜í–¥]

### ë¹„ì¬ë¬´ì§€í‘œ ìœ„í—˜  
[ë¹„ì¬ë¬´ì§€í‘œ ìœ„í—˜ìˆ˜ì¤€ ë° ì„¸ë¶€ì‚¬í•­]

## ğŸ’¡ í•„ìš” ì¡°ì¹˜ì‚¬í•­
### ì¦‰ì‹œ ëŒ€ì‘ í•„ìš”
[ê¸´ê¸‰ ì¡°ì¹˜ì‚¬í•­]

### ì¤‘ì¥ê¸° ê°œì„ ë°©ì•ˆ
[ì „ëµì  ê°œì„ ë°©ì•ˆ]

## ğŸ“ˆ ì¸ì‚¬ì´íŠ¸ ë° ê¶Œê³ ì‚¬í•­
[ë°ì´í„° ê¸°ë°˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ì™€ êµ¬ì²´ì  ê¶Œê³ ì‚¬í•­]
        """)
        
        chain = summary_prompt | self.llm | StrOutputParser()
        
        try:
            # ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ ìš”ì•½
            financial_anomalies = all_results.get("financial_anomalies", {})
            financial_summary = []
            if financial_anomalies:
                for metric, details in financial_anomalies.items():
                    if isinstance(details, dict):
                        severity = details.get("severity", "Medium")
                        desc = details.get("description", "")
                        financial_summary.append(f"- {metric} ({severity}): {desc}")
            
            # ë¹„ì¬ë¬´ì§€í‘œ ìš”ì•½
            nfr_data = all_results.get("non_financial_analysis", {})
            nfr_summary = f"ì „ì²´ ìœ„í—˜ìˆ˜ì¤€: {nfr_data.get('risk_summary', {}).get('overall_risk_level', 'ì•Œ ìˆ˜ ì—†ìŒ')}"
            
            # ê·¼ê±° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
            integrated_data = all_results.get("integrated_anomaly_analysis", [])
            evidence_insights = []
            for anomaly in integrated_data[:3]:  # ìƒìœ„ 3ê°œ
                if isinstance(anomaly, dict):
                    metric = anomaly.get("ë©”íŠ¸ë¦­ëª…", "")
                    news_analysis = anomaly.get("ë‰´ìŠ¤_ë¶„ì„", {})
                    primary_cause = news_analysis.get("ì£¼ìš”_ì›ì¸", "")
                    if primary_cause:
                        evidence_insights.append(f"- {metric}: {primary_cause}")
            
            # AI ìš”ì•½ ìƒì„±
            ai_summary = self.generate_ai_analysis_summary(all_results, risk_assessment)
            
            summary = chain.invoke({
                "company_name": company_info.get("ê¸°ì—…ëª…", "ë¶„ì„ ëŒ€ìƒ ê¸°ì—…"),
                "current_grade": company_info.get("Current_credit_grade", "ì•Œ ìˆ˜ ì—†ìŒ"),
                "new_grade": risk_assessment["grade"],
                "score": risk_assessment["score"],
                "grade": risk_assessment["grade"],
                "risk_level": risk_assessment["risk_level"],
                "financial_anomalies_summary": "\n".join(financial_summary) or "ì´ìƒì¹˜ ì—†ìŒ",
                "non_financial_summary": nfr_summary,
                "evidence_insights": "\n".join(evidence_insights) or "ê·¼ê±° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ì—†ìŒ",
                "ai_summary": ai_summary
            })
            
            return summary
            
        except Exception as e:
            return f"ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def generate_detailed_analysis(self, all_results: Dict[str, Any]) -> str:
        """ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        detailed_prompt = ChatPromptTemplate.from_template(
"""
ë‹¤ìŒ ì¢…í•© ì‹ ìš©ìœ„í—˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
ê·¼ê±°ëŠ” ë°˜ë“œì‹œ {integrated_analysis}ì—ì„œ ì§ì ‘ ë°œì·Œí•œ ë¬¸ì¥ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”.

## ì¬ë¬´ì§€í‘œ ë¶„ì„ ê²°ê³¼
{financial_data}

## ë¹„ì¬ë¬´ì§€í‘œ ë¶„ì„ ê²°ê³¼  
{non_financial_data}

## í†µí•© ì´ìƒì¹˜ ë¶„ì„ (ê·¼ê±° ë°ì´í„°)
í•´ë‹¹ ê·¼ê±° ë°ì´í„°ë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
{integrated_analysis}

ë‹¤ìŒ êµ¬ì¡°ë¡œ ìƒì„¸ ë¶„ì„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

## 1. ì¬ë¬´ ìœ„í—˜ ë¶„ì„
- íƒì§€ëœ ì´ìƒì¹˜ì™€ ê·¸ ì˜ë¯¸
- ì´ìƒì¹˜ì— ëŒ€í•œ ë‰´ìŠ¤ ê·¼ê±° : ë‰´ìŠ¤ ì œëª©, url, ë‚´ìš© ì¼ë¶€ 
- ì´ìƒì¹˜ì— ëŒ€í•œ ë¹„ì¬ë¬´ ê·¼ê±° : ë³´ê³ ì„œ ì¢…ë¥˜, ê´€ë ¨ ë¬¸ì¥ 
- ë¶„ê¸°ë³„ ì¬ë¬´ì§€í‘œ ë³€í™” íŠ¸ë Œë“œ
- ë™ì¢…ì—…ê³„ ëŒ€ë¹„ ìƒëŒ€ì  ìœ„ì¹˜

## 2. ë¹„ì¬ë¬´ ìœ„í—˜ ë¶„ì„
- 5ê°œ í•µì‹¬ ì˜ì—­ë³„ ìœ„í—˜ë„ í‰ê°€ (ì‚°ì—…ìœ„í—˜, ê²½ì˜ìœ„í—˜, ì˜ì—…ìœ„í—˜, ì¬ë¬´ìœ„í—˜(ì§ˆì ), ì‹ ë¢°ë„)
- ì •ê¸°ë³´ê³ ì„œ ê¸°ë°˜ ì§ˆì  ìœ„í—˜ ìš”ì†Œ
- ê±°ë²„ë„ŒìŠ¤ ë° ìš´ì˜ ìœ„í—˜ 

## 3. ê·¼ê±° ê¸°ë°˜ ì›ì¸ ë¶„ì„
- ê° ì´ìƒì¹˜ì˜ ê·¼ë³¸ ì›ì¸ê³¼ ì¦ê±° 
- ë‰´ìŠ¤ ë° ì‹œì¥ ì •ë³´ ê¸°ë°˜ ì™¸ë¶€ ìš”ì¸ ë¶„ì„(ê·¼ê±°ë¬¸ì¥, url ë„ì¶œ)
- ë‚´ë¶€ ê²½ì˜ì§„ì˜ ì˜ì‚¬ê²°ì • ì˜í–¥

## 4. í†µí•© ë¶„ì„ ë° ì¢…í•© ì˜ê²¬
- ì¬ë¬´Â·ë¹„ì¬ë¬´ ë¶„ì„ì˜ ì¼ê´€ì„±
- ì¢…í•©ì  ìœ„í—˜ í‰ê°€
- í–¥í›„ ì „ë§ ë° ì‹œë‚˜ë¦¬ì˜¤
""")
        
        chain = detailed_prompt | self.llm | StrOutputParser()
        
        try:
            detailed_analysis = chain.invoke({
                "financial_data": json.dumps(all_results.get("financial_anomalies"), ensure_ascii=False, indent=2) if all_results.get("financial_anomalies") else "ì¬ë¬´ ì´ìƒì¹˜ ì—†ìŒ",
                "non_financial_data": json.dumps(all_results.get("non_financial_analysis"), ensure_ascii=False, indent=2) if all_results.get("non_financial_analysis") else "ë¹„ì¬ë¬´ ë¶„ì„ ê²°ê³¼ ì—†ìŒ",
                "integrated_analysis": json.dumps(all_results.get("integrated_anomaly_analysis"), ensure_ascii=False, indent=2) if all_results.get("integrated_anomaly_analysis") else "í†µí•© ë¶„ì„ ê²°ê³¼ ì—†ìŒ"
            })
            
            return detailed_analysis
            
        except Exception as e:
            return f"ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def generate_integrated_report_from_dir(self, result_dir: str) -> Dict[str, Any]:
        """
        ë¶„ì„ ê²°ê³¼ ë””ë ‰í† ë¦¬ë¡œë¶€í„° í†µí•© ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            result_dir: ë¶„ì„ ê²°ê³¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            
        Returns:
            Dict: í†µí•© ë¦¬í¬íŠ¸
        """
        
        print(f"ğŸ“Š í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘... (ê²°ê³¼ ë””ë ‰í† ë¦¬: {result_dir})")
        
        # 1. ëª¨ë“  ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        all_results = self.load_analysis_results(result_dir)
        
        # ê¸°ì—… ì •ë³´ ì¶”ì¶œ
        financial_data = all_results.get("financial_analysis", {})
        company_info = financial_data.get("ê¸°ì—…_ì •ë³´", {})
        company_name = company_info.get("ê¸°ì—…ëª…", "ë¶„ì„ ëŒ€ìƒ ê¸°ì—…")
        
        # 2. ì¢…í•© ìœ„í—˜ í‰ê°€
        risk_assessment = self._calculate_comprehensive_risk_score(all_results)
        
        # 3. AI ë¶„ì„ ìš”ì•½ ìƒì„±
        ai_summary = self.generate_ai_analysis_summary(all_results, risk_assessment)
        
        # 4. ë¶„ê¸°ë³„ íŠ¸ë Œë“œ ë¶„ì„
        quarterly_trends = self._extract_quarterly_trend_data(financial_data)
        
        # 5. ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰
        similar_cases = self._find_similar_cases(all_results.get("financial_anomalies", {}), company_info)
        
        # 6. ê²½ì˜ì§„ìš© ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
        executive_summary = self.generate_executive_summary(all_results, risk_assessment, company_info)
        
        # 7. ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        detailed_analysis = self.generate_detailed_analysis(all_results)
        
        # 8. ìµœì¢… JSON ë¦¬í¬íŠ¸ êµ¬ì„±
        final_report_json = {
            "ë¶„ì„_ë©”íƒ€ë°ì´í„°": {
                "ìƒì„±_ì‹œê°„": datetime.now().isoformat(),
                "ë¶„ì„_ëŒ€ìƒ": company_name,
                "ë¶„ì„_ë²„ì „": "3.0",
                "ê²°ê³¼_ë””ë ‰í† ë¦¬": result_dir
            },
            "ê¸°ì—…_ì •ë³´": company_info,
            "AI_ì¢…í•©_ë¶„ì„_ìš”ì•½": ai_summary,
            "ì˜ˆìƒ_ì‹ ìš©ë“±ê¸‰_ë³€í™”": {
                "í˜„ì¬_ë“±ê¸‰": company_info.get("Current_credit_grade", "ì•Œ ìˆ˜ ì—†ìŒ"),
                "ì˜ˆìƒ_ë“±ê¸‰": risk_assessment["grade"],
                "ë“±ê¸‰_ë³€í™”_ì‚¬ìœ ": "ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ ë° ë¹„ì¬ë¬´ ìœ„í—˜ìš”ì†Œ ì¢…í•© í‰ê°€ ê²°ê³¼"
            },
            "ì¬ë¬´ì§€í‘œ_ë¶„ì„": {
                "ì´ìƒì¹˜_ëª©ë¡": all_results.get("financial_anomalies", {}),
                "í†µí•©_ê·¼ê±°_ë¶„ì„": all_results.get("integrated_anomaly_analysis", []),
                "ë¶„ê¸°ë³„_ë³€í™”_ì¶”ì´": quarterly_trends,
                "ìœ„í—˜ë„_í‰ê°€": risk_assessment["breakdown"]
            },
            "ë¹„ì¬ë¬´ì§€í‘œ_ë¶„ì„": {
                "ì´ìƒì¹˜_íƒì§€_ê¸°ì¤€": "5ê°œ í•µì‹¬ ì˜ì—­ í‰ê°€ (ì‚°ì—…ìœ„í—˜, ê²½ì˜ìœ„í—˜, ì˜ì—…ìœ„í—˜, ì¬ë¬´ìœ„í—˜(ì§ˆì ), ì‹ ë¢°ë„)",
                "íƒì§€ëœ_ì´ìƒì¹˜": all_results.get("non_financial_analysis", {}).get("latest_quarter_results", []),
                "ìœ„í—˜ë„": all_results.get("non_financial_analysis", {}).get("risk_summary", {}),
            },
            "ìœ ì‚¬_ì‚¬ë¡€_ë¶„ì„": similar_cases,
            "ì¢…í•©_ìœ„í—˜í‰ê°€": risk_assessment,
        }
        
        # 9. í†µí•© ë¦¬í¬íŠ¸ êµ¬ì„±
        integrated_report = {
            "metadata": {
                "company_name": company_name,
                "analysis_date": datetime.now().isoformat(),
                "report_version": "3.0",
                "analyst": "AI Credit Risk Analyzer",
                "result_directory": result_dir
            },
            "risk_assessment": risk_assessment,
            "executive_summary": executive_summary,
            "detailed_analysis": detailed_analysis,
            "final_report_json": final_report_json,
            "source_data": {
                "financial_analysis_available": all_results.get("financial_analysis") is not None,
                "financial_anomalies_available": all_results.get("financial_anomalies") is not None,
                "non_financial_analysis_available": all_results.get("non_financial_analysis") is not None,
                "integrated_analysis_available": all_results.get("integrated_anomaly_analysis") is not None
            }
        }
        
        return integrated_report


def generate_final_report(result_dir: str) -> Dict[str, Any]:
    """
    ê²°ê³¼ ë””ë ‰í† ë¦¬ë¡œë¶€í„° ìµœì¢… í†µí•© ë¦¬í¬íŠ¸ ìƒì„± (ë©”ì¸ í•¨ìˆ˜)
    
    Args:
        result_dir: ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        
    Returns:
        Dict: í†µí•© ë¦¬í¬íŠ¸
    """
    
    generator = CreditRiskReportGenerator()
    integrated_report = generator.generate_integrated_report_from_dir(result_dir)
    
    # JSON ë¦¬í¬íŠ¸ ì €ì¥
    json_report_path = os.path.join(result_dir, "final_comprehensive_report.json")
    with open(json_report_path, 'w', encoding='utf-8') as f:
        json.dump(integrated_report["final_report_json"], f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“„ ìµœì¢… JSON ë¦¬í¬íŠ¸ ì €ì¥: {json_report_path}")
    
    return integrated_report


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_result_dir = "analysis_results/ì‚¼ì„±ì „ì"
    
    try:
        report = generate_final_report(test_result_dir)
        
        print("=== í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ ===")
        print(f"ê¸°ì—…ëª…: {report['metadata']['company_name']}")
        print(f"ì¢…í•© ë“±ê¸‰: {report['risk_assessment']['grade']}")
        print(f"ìœ„í—˜ ìˆ˜ì¤€: {report['risk_assessment']['risk_level']}")
        print(f"ì¢…í•© ì ìˆ˜: {report['risk_assessment']['score']}/100")
        
        # ìš”ì•½ ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        print("\n=== ê²½ì˜ì§„ìš© ìš”ì•½ (ë¯¸ë¦¬ë³´ê¸°) ===")
        summary = report['executive_summary']
        print(summary[:500] + "..." if len(summary) > 500 else summary)
        
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")