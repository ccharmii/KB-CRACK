# /KB-CRACK/report_generator.py
# ì¬ë¬´ ë° ë¹„ì¬ë¬´ ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ìµœì¢… ì‹ ìš©ìœ„í—˜ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±


"""
í†µí•© ì‹ ìš©ìœ„í—˜ ë¶„ì„ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±ê¸°
ë‰´ìŠ¤ ë¶„ì„ì„ ì œì™¸í•œ ì¬ë¬´ì§€í‘œ, ë¹„ì¬ë¬´ì§€í‘œ, ê·¼ê±° ë¶„ì„ì„ í†µí•©í•˜ì—¬ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any

from dotenv import load_dotenv
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

load_dotenv()


class CreditRiskReportGenerator:
    """ì‹ ìš©ìœ„í—˜ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""

    def __init__(self, model: str = "gpt-4o-mini"):
        """
        ë¦¬í¬íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™”

        ì…ë ¥: model(ì‚¬ìš©í•  LLM ëª¨ë¸ëª…)
        """
        self.llm = ChatOpenAI(model=model, temperature=0.3)

    def load_analysis_results(self, result_dir: str) -> Dict[str, Any]:
        """
        ë¶„ì„ ê²°ê³¼ ë””ë ‰í„°ë¦¬ì—ì„œ ë¶„ì„ ì‚°ì¶œë¬¼ì„ ë¡œë“œ

        ì…ë ¥: result_dir(ë¶„ì„ ê²°ê³¼ ë””ë ‰í„°ë¦¬ ê²½ë¡œ)
        ì¶œë ¥: ì¬ë¬´ë¶„ì„, ì¬ë¬´ ì´ìƒì¹˜, ë¹„ì¬ë¬´ë¶„ì„, í†µí•© ì´ìƒì¹˜ ë¶„ì„ì„ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        results: Dict[str, Any] = {
            "financial_analysis": None,
            "financial_anomalies": None,
            "non_financial_analysis": None,
            "integrated_anomaly_analysis": None,
        }

        financial_analysis_file = os.path.join(result_dir, "financial_analysis.json")
        if os.path.exists(financial_analysis_file):
            try:
                with open(financial_analysis_file, "r", encoding="utf-8") as f:
                    results["financial_analysis"] = json.load(f)
                print("ì¬ë¬´ë¶„ì„ ì›ë³¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"ì¬ë¬´ë¶„ì„ ì›ë³¸ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")

        financial_anomalies_file = os.path.join(result_dir, "financial_anomalies.json")
        if os.path.exists(financial_anomalies_file):
            try:
                with open(financial_anomalies_file, "r", encoding="utf-8") as f:
                    results["financial_anomalies"] = json.load(f)
                count = len(results["financial_anomalies"]) if results["financial_anomalies"] else 0
                print(f"ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ ë¡œë“œ ì™„ë£Œ: {count}ê°œ")
            except Exception as e:
                print(f"ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")

        nfr_file = os.path.join(result_dir, "non_financial_analysis.json")
        if os.path.exists(nfr_file):
            try:
                with open(nfr_file, "r", encoding="utf-8") as f:
                    results["non_financial_analysis"] = json.load(f)
                print("ë¹„ì¬ë¬´ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"ë¹„ì¬ë¬´ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")

        integrated_file = os.path.join(result_dir, "integrated_anomaly_report.json")
        if os.path.exists(integrated_file):
            try:
                with open(integrated_file, "r", encoding="utf-8") as f:
                    integrated_data = json.load(f)
                results["integrated_anomaly_analysis"] = integrated_data.get("í†µí•©_ì´ìƒì¹˜_ë¶„ì„", [])
                print("í†µí•© ì´ìƒì¹˜ ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"í†µí•© ì´ìƒì¹˜ ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")

        return results

    def _calculate_comprehensive_risk_score(self, all_results: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì¬ë¬´ ë° ë¹„ì¬ë¬´ ìš”ì¸ì„ ì¢…í•©í•˜ì—¬ ìœ„í—˜ ì ìˆ˜ì™€ ë“±ê¸‰ì„ ì‚°ì¶œ

        ì…ë ¥: all_results(ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬)
        ì¶œë ¥: score, grade, risk_level, breakdown, component_scoresë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        base_score = 100

        financial_penalty = 0
        financial_anomalies = all_results.get("financial_anomalies")
        if financial_anomalies:
            for _, details in financial_anomalies.items():
                severity = details.get("severity", "Medium") if isinstance(details, dict) else "Medium"
                if severity == "High":
                    financial_penalty += 15
                elif severity == "Medium":
                    financial_penalty += 8
                else:
                    financial_penalty += 3

        nfr_penalty = 0
        nfr_data = all_results.get("non_financial_analysis")
        if nfr_data:
            risk_summary = nfr_data.get("risk_summary", {})
            risk_level = risk_summary.get("overall_risk_level", "ë³´í†µ")

            if risk_level == "ë†’ìŒ":
                nfr_penalty += 25
            elif risk_level == "ì£¼ì˜":
                nfr_penalty += 15
            elif risk_level == "ë³´í†µ":
                nfr_penalty += 8

            latest_results = nfr_data.get("latest_quarter_results", [])
            for result in latest_results:
                score = result.get("score", 3)
                if score <= 1:
                    nfr_penalty += 5
                elif score <= 2:
                    nfr_penalty += 3

        final_score = max(0, base_score - financial_penalty - nfr_penalty)

        if final_score >= 90:
            grade = "AAA"
            risk_level = "ë§¤ìš° ë‚®ìŒ"
        elif final_score >= 80:
            grade = "AA"
            risk_level = "ë‚®ìŒ"
        elif final_score >= 70:
            grade = "A"
            risk_level = "ë³´í†µ"
        elif final_score >= 60:
            grade = "BBB"
            risk_level = "ì£¼ì˜"
        elif final_score >= 50:
            grade = "BB"
            risk_level = "ìœ„í—˜"
        else:
            grade = "B"
            risk_level = "ê³ ìœ„í—˜"

        return {
            "score": final_score,
            "grade": grade,
            "risk_level": risk_level,
            "breakdown": {
                "financial_penalty": financial_penalty,
                "non_financial_penalty": nfr_penalty,
            },
            "component_scores": {
                "financial": max(0, 100 - financial_penalty),
                "non_financial": max(0, 100 - nfr_penalty),
            },
        }

    def _extract_quarterly_trend_data(self, financial_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ë¶„ê¸°ë³„ ì£¼ìš” ì¬ë¬´ì§€í‘œ ë³€í™”ìœ¨ì„ ê³„ì‚°í•˜ì—¬ ì¶”ì„¸ ë°ì´í„°ë¥¼ ìƒì„±

        ì…ë ¥: financial_data(ì¬ë¬´ ë¶„ì„ ì›ë³¸ ë°ì´í„°)
        ì¶œë ¥: ë¶„ê¸°ë³„ ì§€í‘œ ë³€í™” ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
        """
        if not financial_data:
            return {}

        quarterly_data = financial_data.get("ì£¼ìš”ì§€í‘œ_ì‹œê³„ì—´_ë¶„ì„", {})
        sorted_quarters = sorted(quarterly_data.keys())

        trend_analysis: Dict[str, Any] = {}

        for i, quarter in enumerate(sorted_quarters):
            if i == 0:
                continue

            prev_quarter = sorted_quarters[i - 1]
            current_data = quarterly_data.get(quarter, {})
            prev_data = quarterly_data.get(prev_quarter, {})

            quarter_trend: Dict[str, Any] = {}
            for metric, current_value in current_data.items():
                if metric not in prev_data:
                    continue

                prev_value = prev_data[metric]
                if prev_value == 0:
                    continue

                change_rate = ((current_value - prev_value) / prev_value) * 100
                quarter_trend[metric] = {
                    "current": current_value,
                    "previous": prev_value,
                    "change_rate": round(change_rate, 2),
                    "direction": "ì¦ê°€" if change_rate > 0 else "ê°ì†Œ" if change_rate < 0 else "ë³€í™”ì—†ìŒ",
                }

            trend_analysis[quarter] = quarter_trend

        return trend_analysis

    def _find_similar_cases(self, anomalies: Dict[str, Any], company_info: Dict[str, Any]) -> List[Dict]:
        """ì´ìƒì¹˜ íŒ¨í„´ì— ëŒ€í•œ ìœ ì‚¬ ì‚¬ë¡€ ëª©ë¡ ë°˜í™˜"""
        similar_cases = [
            {
                "company": "LGì „ì",
                "year": "2023",
                "anomaly_type": "ROE í•˜ë½",
                "initial_grade": "A+",
                "final_grade": "A",
                "recovery_period": "6ê°œì›”",
                "actions_taken": ["ë¹„ìš©ì ˆê°", "ì‚¬ì—…êµ¬ì¡° ê°œí¸", "R&D íˆ¬ì ì¦ëŒ€"],
            },
            {
                "company": "SKí•˜ì´ë‹‰ìŠ¤",
                "year": "2022",
                "anomaly_type": "ë§¤ì¶œì•¡ì¦ê°€ìœ¨ ë‘”í™”",
                "initial_grade": "AA-",
                "final_grade": "A+",
                "recovery_period": "9ê°œì›”",
                "actions_taken": ["ì‹ ì œí’ˆ ì¶œì‹œ", "í•´ì™¸ì‹œì¥ í™•ì¥", "ì›ê°€ì ˆê°"],
            },
        ]
        return similar_cases

    def generate_ai_analysis_summary(self, all_results: Dict[str, Any], risk_assessment: Dict[str, Any]) -> str:
        """
        ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ LLMìœ¼ë¡œ ìƒì„±

        ì…ë ¥: all_results(ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬), risk_assessment(ìœ„í—˜ í‰ê°€ ê²°ê³¼)
        ì¶œë ¥: 1~2ì¤„ ìš”ì•½ ë¬¸ìì—´
        """
        summary_prompt = ChatPromptTemplate.from_template(
            """
ë‹¹ì‹ ì€ ì‹ ìš©ìœ„í—˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ 1-2ì¤„ì˜ ê°„ê²°í•œ AI ì¢…í•© ë¶„ì„ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜: {financial_anomalies_count}ê°œ
ë¹„ì¬ë¬´ì§€í‘œ ìœ„í—˜ìˆ˜ì¤€: {nfr_risk_level}
ì¢…í•© ìœ„í—˜ë“±ê¸‰: {risk_grade}
ì¢…í•© ì ìˆ˜: {risk_score}/100

í•µì‹¬ ì´ìƒì¹˜:
{key_anomalies}

1-2ì¤„ë¡œ í•µì‹¬ ë¦¬ìŠ¤í¬ì™€ ì „ë°˜ì ì¸ ì‹ ìš©ìƒíƒœë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.
            """
        )

        chain = summary_prompt | self.llm | StrOutputParser()

        try:
            financial_anomalies = all_results.get("financial_anomalies", {})
            nfr_data = all_results.get("non_financial_analysis", {})

            key_anomalies: List[str] = []
            if financial_anomalies:
                for metric, details in list(financial_anomalies.items())[:3]:
                    if isinstance(details, dict):
                        key_anomalies.append(f"- {metric}: {details.get('description', '')}")

            summary = chain.invoke(
                {
                    "financial_anomalies_count": len(financial_anomalies) if financial_anomalies else 0,
                    "nfr_risk_level": nfr_data.get("risk_summary", {}).get("overall_risk_level", "ì•Œ ìˆ˜ ì—†ìŒ"),
                    "risk_grade": risk_assessment["grade"],
                    "risk_score": risk_assessment["score"],
                    "key_anomalies": "\n".join(key_anomalies) or "ì£¼ìš” ì´ìƒì¹˜ ì—†ìŒ",
                }
            )

            return summary.strip()
        except Exception as e:
            return f"AI ë¶„ì„ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    def generate_executive_summary(
        self,
        all_results: Dict[str, Any],
        risk_assessment: Dict[str, Any],
        company_info: Dict[str, Any],
    ) -> str:
        """
        ê²½ì˜ì§„ìš© ìš”ì•½ ë¦¬í¬íŠ¸ë¥¼ LLMìœ¼ë¡œ ìƒì„±

        ì…ë ¥: all_results(ë¶„ì„ ê²°ê³¼), risk_assessment(ìœ„í—˜ í‰ê°€), company_info(ê¸°ì—… ì •ë³´)
        ì¶œë ¥: ê²½ì˜ì§„ìš© ìš”ì•½ ë¦¬í¬íŠ¸ ë¬¸ìì—´
        """
        summary_prompt = ChatPromptTemplate.from_template(
            """
ë‹¹ì‹ ì€ ì‹ ìš©ìœ„í—˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²½ì˜ì§„ìš© ì¢…í•© ìš”ì•½ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

## ê¸°ì—… ì •ë³´
ê¸°ì—…ëª…: {company_name}
í˜„ì¬ ì‹ ìš©ë“±ê¸‰: {current_grade}
ë¶„ì„ ëŒ€ìƒ ë“±ê¸‰: {new_grade}

## ì¢…í•© ìœ„í—˜ í‰ê°€
- ì ìˆ˜: {score}ì /100ì 
- ë“±ê¸‰: {grade}
- ìœ„í—˜ìˆ˜ì¤€: {risk_level}

## ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ ë¶„ì„
{financial_anomalies_summary}

## ë¹„ì¬ë¬´ì§€í‘œ ë¶„ì„
{non_financial_summary}

## ê·¼ê±° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
{evidence_insights}

ë‹¤ìŒ êµ¬ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

# {company_name} ì‹ ìš©ìœ„í—˜ ë¶„ì„ ìš”ì•½ ë¦¬í¬íŠ¸

## ğŸ” AI ì¢…í•© ë¶„ì„ ìš”ì•½
{ai_summary}

## ğŸ“Š ì˜ˆìƒ ì‹ ìš©ë“±ê¸‰ ë³€í™”
í˜„ì¬: {current_grade} â†’ ì˜ˆìƒ: {new_grade}
ë³€í™” ì‚¬ìœ : [ì£¼ìš” ìœ„í—˜ìš”ì¸ ìš”ì•½]

## âš ï¸ ì£¼ìš” ìœ„í—˜ ìš”ì†Œ
### ì¬ë¬´ì§€í‘œ ìœ„í—˜
[ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ë³„ ìœ„í—˜ë„ ë° ì˜í–¥]

### ë¹„ì¬ë¬´ì§€í‘œ ìœ„í—˜  
[ë¹„ì¬ë¬´ì§€í‘œ ìœ„í—˜ìˆ˜ì¤€ ë° ì„¸ë¶€ì‚¬í•­]

## ğŸ’¡ í•„ìš” ì¡°ì¹˜ì‚¬í•­
### ì¦‰ì‹œ ëŒ€ì‘ í•„ìš”
[ê¸´ê¸‰ ì¡°ì¹˜ì‚¬í•­]

### ì¤‘ì¥ê¸° ê°œì„ ë°©ì•ˆ
[ì „ëµì  ê°œì„ ë°©ì•ˆ]

## ğŸ“ˆ ì¸ì‚¬ì´íŠ¸ ë° ê¶Œê³ ì‚¬í•­
[ë°ì´í„° ê¸°ë°˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ì™€ êµ¬ì²´ì  ê¶Œê³ ì‚¬í•­]
            """
        )

        chain = summary_prompt | self.llm | StrOutputParser()

        try:
            financial_anomalies = all_results.get("financial_anomalies", {})
            financial_summary: List[str] = []
            if financial_anomalies:
                for metric, details in financial_anomalies.items():
                    if isinstance(details, dict):
                        severity = details.get("severity", "Medium")
                        desc = details.get("description", "")
                        financial_summary.append(f"- {metric} ({severity}): {desc}")

            nfr_data = all_results.get("non_financial_analysis", {})
            nfr_summary = f"ì „ì²´ ìœ„í—˜ìˆ˜ì¤€: {nfr_data.get('risk_summary', {}).get('overall_risk_level', 'ì•Œ ìˆ˜ ì—†ìŒ')}"

            integrated_data = all_results.get("integrated_anomaly_analysis", [])
            evidence_insights: List[str] = []
            for anomaly in integrated_data[:3]:
                if isinstance(anomaly, dict):
                    metric = anomaly.get("ë©”íŠ¸ë¦­ëª…", "")
                    news_analysis = anomaly.get("ë‰´ìŠ¤_ë¶„ì„", {})
                    primary_cause = news_analysis.get("ì£¼ìš”_ì›ì¸", "")
                    if primary_cause:
                        evidence_insights.append(f"- {metric}: {primary_cause}")

            ai_summary = self.generate_ai_analysis_summary(all_results, risk_assessment)

            summary = chain.invoke(
                {
                    "company_name": company_info.get("ê¸°ì—…ëª…", "ë¶„ì„ ëŒ€ìƒ ê¸°ì—…"),
                    "current_grade": company_info.get("Current_credit_grade", "ì•Œ ìˆ˜ ì—†ìŒ"),
                    "new_grade": risk_assessment["grade"],
                    "score": risk_assessment["score"],
                    "grade": risk_assessment["grade"],
                    "risk_level": risk_assessment["risk_level"],
                    "financial_anomalies_summary": "\n".join(financial_summary) or "ì´ìƒì¹˜ ì—†ìŒ",
                    "non_financial_summary": nfr_summary,
                    "evidence_insights": "\n".join(evidence_insights) or "ê·¼ê±° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ì—†ìŒ",
                    "ai_summary": ai_summary,
                }
            )

            return summary
        except Exception as e:
            return f"ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    def generate_detailed_analysis(self, all_results: Dict[str, Any]) -> str:
        """
        ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ LLMìœ¼ë¡œ ìƒì„±

        ì…ë ¥: all_results(ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬)
        ì¶œë ¥: ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ë¬¸ìì—´
        """
        detailed_prompt = ChatPromptTemplate.from_template(
            """
ë‹¤ìŒ ì¢…í•© ì‹ ìš©ìœ„í—˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
ê·¼ê±°ëŠ” ë°˜ë“œì‹œ {integrated_analysis}ì—ì„œ ì§ì ‘ ë°œì·Œí•œ ë¬¸ì¥ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”.

## ì¬ë¬´ì§€í‘œ ë¶„ì„ ê²°ê³¼
{financial_data}

## ë¹„ì¬ë¬´ì§€í‘œ ë¶„ì„ ê²°ê³¼  
{non_financial_data}

## í†µí•© ì´ìƒì¹˜ ë¶„ì„ (ê·¼ê±° ë°ì´í„°)
í•´ë‹¹ ê·¼ê±° ë°ì´í„°ë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
{integrated_analysis}

ë‹¤ìŒ êµ¬ì¡°ë¡œ ìƒì„¸ ë¶„ì„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

## 1. ì¬ë¬´ ìœ„í—˜ ë¶„ì„
- íƒì§€ëœ ì´ìƒì¹˜ì™€ ê·¸ ì˜ë¯¸
- ì´ìƒì¹˜ì— ëŒ€í•œ ë‰´ìŠ¤ ê·¼ê±° : ë‰´ìŠ¤ ì œëª©, url, ë‚´ìš© ì¼ë¶€ 
- ì´ìƒì¹˜ì— ëŒ€í•œ ë¹„ì¬ë¬´ ê·¼ê±° : ë³´ê³ ì„œ ì¢…ë¥˜, ê´€ë ¨ ë¬¸ì¥ 
- ë¶„ê¸°ë³„ ì¬ë¬´ì§€í‘œ ë³€í™” íŠ¸ë Œë“œ
- ë™ì¢…ì—…ê³„ ëŒ€ë¹„ ìƒëŒ€ì  ìœ„ì¹˜

## 2. ë¹„ì¬ë¬´ ìœ„í—˜ ë¶„ì„
- 5ê°œ í•µì‹¬ ì˜ì—­ë³„ ìœ„í—˜ë„ í‰ê°€ (ì‚°ì—…ìœ„í—˜, ê²½ì˜ìœ„í—˜, ì˜ì—…ìœ„í—˜, ì¬ë¬´ìœ„í—˜(ì§ˆì ), ì‹ ë¢°ë„)
- ì •ê¸°ë³´ê³ ì„œ ê¸°ë°˜ ì§ˆì  ìœ„í—˜ ìš”ì†Œ
- ê±°ë²„ë„ŒìŠ¤ ë° ìš´ì˜ ìœ„í—˜ 

## 3. ê·¼ê±° ê¸°ë°˜ ì›ì¸ ë¶„ì„
- ê° ì´ìƒì¹˜ì˜ ê·¼ë³¸ ì›ì¸ê³¼ ì¦ê±° 
- ë‰´ìŠ¤ ë° ì‹œì¥ ì •ë³´ ê¸°ë°˜ ì™¸ë¶€ ìš”ì¸ ë¶„ì„(ê·¼ê±°ë¬¸ì¥, url ë„ì¶œ)
- ë‚´ë¶€ ê²½ì˜ì§„ì˜ ì˜ì‚¬ê²°ì • ì˜í–¥

## 4. í†µí•© ë¶„ì„ ë° ì¢…í•© ì˜ê²¬
- ì¬ë¬´Â·ë¹„ì¬ë¬´ ë¶„ì„ì˜ ì¼ê´€ì„±
- ì¢…í•©ì  ìœ„í—˜ í‰ê°€
- í–¥í›„ ì „ë§ ë° ì‹œë‚˜ë¦¬ì˜¤
            """
        )

        chain = detailed_prompt | self.llm | StrOutputParser()

        try:
            detailed_analysis = chain.invoke(
                {
                    "financial_data": json.dumps(
                        all_results.get("financial_anomalies"), ensure_ascii=False, indent=2
                    )
                    if all_results.get("financial_anomalies")
                    else "ì¬ë¬´ ì´ìƒì¹˜ ì—†ìŒ",
                    "non_financial_data": json.dumps(
                        all_results.get("non_financial_analysis"), ensure_ascii=False, indent=2
                    )
                    if all_results.get("non_financial_analysis")
                    else "ë¹„ì¬ë¬´ ë¶„ì„ ê²°ê³¼ ì—†ìŒ",
                    "integrated_analysis": json.dumps(
                        all_results.get("integrated_anomaly_analysis"), ensure_ascii=False, indent=2
                    )
                    if all_results.get("integrated_anomaly_analysis")
                    else "í†µí•© ë¶„ì„ ê²°ê³¼ ì—†ìŒ",
                }
            )
            return detailed_analysis
        except Exception as e:
            return f"ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    def generate_integrated_report_from_dir(self, result_dir: str) -> Dict[str, Any]:
        """
        ë¶„ì„ ê²°ê³¼ ë””ë ‰í„°ë¦¬ë¥¼ ì…ë ¥ìœ¼ë¡œ í†µí•© ë¦¬í¬íŠ¸ë¥¼ ìƒì„±

        ì…ë ¥: result_dir(ë¶„ì„ ê²°ê³¼ ë””ë ‰í„°ë¦¬ ê²½ë¡œ)
        ì¶œë ¥: metadata, risk_assessment, ë¦¬í¬íŠ¸ ë³¸ë¬¸, ìµœì¢… JSONì„ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        print(f"í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘: {result_dir}")

        all_results = self.load_analysis_results(result_dir)

        financial_data = all_results.get("financial_analysis", {}) or {}
        company_info = financial_data.get("ê¸°ì—…_ì •ë³´", {}) or {}
        company_name = company_info.get("ê¸°ì—…ëª…", "ë¶„ì„ ëŒ€ìƒ ê¸°ì—…")

        risk_assessment = self._calculate_comprehensive_risk_score(all_results)
        ai_summary = self.generate_ai_analysis_summary(all_results, risk_assessment)
        quarterly_trends = self._extract_quarterly_trend_data(financial_data)
        similar_cases = self._find_similar_cases(all_results.get("financial_anomalies", {}) or {}, company_info)
        executive_summary = self.generate_executive_summary(all_results, risk_assessment, company_info)
        detailed_analysis = self.generate_detailed_analysis(all_results)

        final_report_json = {
            "ë¶„ì„_ë©”íƒ€ë°ì´í„°": {
                "ìƒì„±_ì‹œê°„": datetime.now().isoformat(),
                "ë¶„ì„_ëŒ€ìƒ": company_name,
                "ë¶„ì„_ë²„ì „": "3.0",
                "ê²°ê³¼_ë””ë ‰í„°ë¦¬": result_dir,
            },
            "ê¸°ì—…_ì •ë³´": company_info,
            "AI_ì¢…í•©_ë¶„ì„_ìš”ì•½": ai_summary,
            "ì˜ˆìƒ_ì‹ ìš©ë“±ê¸‰_ë³€í™”": {
                "í˜„ì¬_ë“±ê¸‰": company_info.get("Current_credit_grade", "ì•Œ ìˆ˜ ì—†ìŒ"),
                "ì˜ˆìƒ_ë“±ê¸‰": risk_assessment["grade"],
                "ë“±ê¸‰_ë³€í™”_ì‚¬ìœ ": "ì¬ë¬´ì§€í‘œ ì´ìƒì¹˜ ë° ë¹„ì¬ë¬´ ìœ„í—˜ìš”ì†Œ ì¢…í•© í‰ê°€ ê²°ê³¼",
            },
            "ì¬ë¬´ì§€í‘œ_ë¶„ì„": {
                "ì´ìƒì¹˜_ëª©ë¡": all_results.get("financial_anomalies", {}) or {},
                "í†µí•©_ê·¼ê±°_ë¶„ì„": all_results.get("integrated_anomaly_analysis", []) or [],
                "ë¶„ê¸°ë³„_ë³€í™”_ì¶”ì´": quarterly_trends,
                "ìœ„í—˜ë„_í‰ê°€": risk_assessment["breakdown"],
            },
            "ë¹„ì¬ë¬´ì§€í‘œ_ë¶„ì„": {
                "ì´ìƒì¹˜_íƒì§€_ê¸°ì¤€": "5ê°œ í•µì‹¬ ì˜ì—­ í‰ê°€ (ì‚°ì—…ìœ„í—˜, ê²½ì˜ìœ„í—˜, ì˜ì—…ìœ„í—˜, ì¬ë¬´ìœ„í—˜(ì§ˆì ), ì‹ ë¢°ë„)",
                "íƒì§€ëœ_ì´ìƒì¹˜": (all_results.get("non_financial_analysis", {}) or {}).get(
                    "latest_quarter_results", []
                ),
                "ìœ„í—˜ë„": (all_results.get("non_financial_analysis", {}) or {}).get("risk_summary", {}),
            },
            "ìœ ì‚¬_ì‚¬ë¡€_ë¶„ì„": similar_cases,
            "ì¢…í•©_ìœ„í—˜í‰ê°€": risk_assessment,
        }

        integrated_report = {
            "metadata": {
                "company_name": company_name,
                "analysis_date": datetime.now().isoformat(),
                "report_version": "3.0",
                "analyst": "AI Credit Risk Analyzer",
                "result_directory": result_dir,
            },
            "risk_assessment": risk_assessment,
            "executive_summary": executive_summary,
            "detailed_analysis": detailed_analysis,
            "final_report_json": final_report_json,
            "source_data": {
                "financial_analysis_available": all_results.get("financial_analysis") is not None,
                "financial_anomalies_available": all_results.get("financial_anomalies") is not None,
                "non_financial_analysis_available": all_results.get("non_financial_analysis") is not None,
                "integrated_analysis_available": all_results.get("integrated_anomaly_analysis") is not None,
            },
        }

        return integrated_report


def generate_final_report(result_dir: str) -> Dict[str, Any]:
    """
    ê²°ê³¼ ë””ë ‰í„°ë¦¬ì—ì„œ ìµœì¢… JSON ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ê³  ì €ì¥

    ì…ë ¥: result_dir(ë¶„ì„ ê²°ê³¼ ë””ë ‰í„°ë¦¬ ê²½ë¡œ)
    ì¶œë ¥: í†µí•© ë¦¬í¬íŠ¸ ë”•ì…”ë„ˆë¦¬
    """
    generator = CreditRiskReportGenerator()
    integrated_report = generator.generate_integrated_report_from_dir(result_dir)

    json_report_path = os.path.join(result_dir, "final_comprehensive_report.json")
    with open(json_report_path, "w", encoding="utf-8") as f:
        json.dump(integrated_report["final_report_json"], f, ensure_ascii=False, indent=2)

    print(f"ìµœì¢… JSON ë¦¬í¬íŠ¸ ì €ì¥: {json_report_path}")

    return integrated_report


if __name__ == "__main__":
    test_result_dir = "analysis_results/ì‚¼ì„±ì „ì"

    try:
        report = generate_final_report(test_result_dir)

        print("í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        print(f"ê¸°ì—…ëª…: {report['metadata']['company_name']}")
        print(f"ì¢…í•© ë“±ê¸‰: {report['risk_assessment']['grade']}")
        print(f"ìœ„í—˜ ìˆ˜ì¤€: {report['risk_assessment']['risk_level']}")
        print(f"ì¢…í•© ì ìˆ˜: {report['risk_assessment']['score']}/100")

        summary = report["executive_summary"]
        preview = (summary[:500] + "...") if len(summary) > 500 else summary
        print("ê²½ì˜ì§„ìš© ìš”ì•½ ë¯¸ë¦¬ë³´ê¸°")
        print(preview)

    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
